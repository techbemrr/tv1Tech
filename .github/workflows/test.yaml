name: T4 (Shards 15–19)

on:
  workflow_dispatch:   # Manual run
  schedule:
    # 5:33 PM IST = 12:03 UTC
    # Runs ONLY Monday–Friday
    - cron: '10 12 * * 1-5'

jobs:
  scrape:
    runs-on: ubuntu-22.04

    strategy:
      fail-fast: false
      max-parallel: 2
      matrix:
        shard: [15,16,17,18,19]

    env:
      SHARD_STEP: 20

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: pip install selenium beautifulsoup4 gspread webdriver-manager

      - name: Write credentials
        run: |
          echo '${{ secrets.GSPREAD_CREDENTIALS }}' > credentials.json
          echo '${{ secrets.TRADINGVIEW_COOKIES }}' > cookies.json

      - name: Init checkpoint
        run: |
          FILE="checkpoint_group4_${{ matrix.shard }}.txt"
          [ ! -f "$FILE" ] && echo "1" > "$FILE"

      - name: Run scraper
        env:
          SHARD_INDEX: ${{ matrix.shard }}
          CHECKPOINT_FILE: checkpoint_group4_${{ matrix.shard }}.txt
        run: python test.py
